model:
  device: 'cuda'

  transformer:
    hidden_dim: 512
    nheads: 8
    enc_layers: 6
    dec_layers: 6
    dim_feedforward: 1024
    dropout: 0.1
    num_feature_levels: 3
    enc_n_points: 4
    dec_n_points: 4
    num_queries: 100
    position_embedding_scale: False
    num_ctrl_points: 16
    num_chars: 25
    voc_size: 100
    use_polygon: True
    aux_loss: False

optimizer:
  path: torch.optim.AdamW
  params:
    lr: 5e-4
    betas: [0.9, 0.999]
    weight_decay: 0.0005

scheduler:
  path: torch.optim.lr_scheduler.CyclicLR
  interval: step
  params:
    base_lr: 0.0001
    max_lr: 0.0075
    step_size_up: 250
    step_size_down: 1000
    mode: "triangular"
    cycle_momentum: false

general:
  logs_dir: logs
  model_name: automation
  exp_name: full_train
  logger_type: clearml

trainer:
  accelerator: 'gpu'
  devices: [ 0, 1 ]
  strategy: 'ddp'
  accumulate_grad_batches: 1
  max_epochs: 500
  log_every_n_steps: 5
  gradient_clip_val: 0.5
  num_sanity_val_steps: 10
  check_val_every_n_epoch: 1
  fast_dev_run: false
  precision: 16

training:
  seed: 17
  log_images_every_n_epoch: 5
  log_max: 8
  dataloader_params:
    batch_size: 42
    num_workers: 2
    pin_memory: true
    shuffle: true
    drop_last: false

validate:
  log_images_every_n_epoch: 5
  log_max: 8
  dataloader_params:
    batch_size: 64
    pin_memory: true
    num_workers: 2
    shuffle: false
    drop_last: false

test:
  dataloader_params:
    batch_size: 16
    pin_memory: true
    num_workers: 2
    shuffle: false
    drop_last: false

callbacks:
  checkpoint:
    mode: min
    monitor: val_losses/val_loss
    save_top_k: 1
    save_last: true
    verbose: true
  early_stopping:
    monitor: val_losses/val_loss
    mode: min
    min_delta: 0
    patience: 30
    verbose: true
